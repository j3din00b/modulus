{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcca3e7-0339-44b5-9e21-c0dea4360f92",
   "metadata": {},
   "source": [
    "# Tutorial 3: Collation and GNNs\n",
    "\n",
    "In the previous tutorials, we saw how to use `readers` to pull data from disk, `transforms` to manipulate that data, and `datasets` to put it all together for one instance of data.  `dataloaders` help batch the data, but we had some implicit assumptions about how to put that data together: stack it onto a new axis at the front of the batch.\n",
    "\n",
    "For some applications, like graph neural networks, that doesn't work.  We need a new way to *collate* the data together.  In this tutorial we'll see how to take the graph data generated for tutorial 2, find the k-Nearest-Neighbors for each point, and use those neighbors to build a batched graph for frameworks like PyTorch Geometric (used in many `physicsnemo` graph models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b92b5f-c454-455c-96e3-6f62f84e8901",
   "metadata": {},
   "source": [
    "> NOTE: you need torch_geometric for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed35dcf-9045-42ab-ad89-925bbaaa3248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp DeprecationWarning: The namespace `warp.context` will soon be removed from the public API. It can still be accessed from `warp._src.context` but might be changed or removed without notice.\n",
      "Warp DeprecationWarning: The symbol `warp.context.Device` will soon be removed from the public API. Use `warp.Device` instead.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, Sequence\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Batch as PyGBatch\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "# Import core datapipe components\n",
    "from physicsnemo.datapipes import DataLoader, Dataset\n",
    "from physicsnemo.datapipes.collate import Collator\n",
    "from physicsnemo.datapipes.readers import ZarrReader\n",
    "from physicsnemo.datapipes.transforms import (\n",
    "    KNearestNeighbors,\n",
    "    SubsamplePoints,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca1b798-ed06-4310-b59e-f384aa0fd678",
   "metadata": {},
   "source": [
    "## Section 1: Dynamically compute kNN on the points, on the fly\n",
    "\n",
    "Many graphs come with edge information already available.  Other data, such as point cloud data, comes unstructured.  We can generate a structure on the fly with kNN operations, here backed by optimized tree searches with `physicsnemo`'s knn function.  On CPU, this will call `scipy'`s KDTree operation, while on GPU this will dispatch to `RAPIDs` neighbor utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a90ac-efa9-47b2-b188-056b8fcc2a58",
   "metadata": {},
   "source": [
    "> NOTE: You will want either scipy or cuml installed for this operation on CPU or GPU, respectively.  Otherwise, `knn` will fall back to a brute force implementation and run out of memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0139975b-343a-41d1-a08d-0307522f2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf72572-bb07-415e-b097-32c0e0d78fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample with 65795 points\n",
      "Fields: ['features', 'coords']\n",
      "\n",
      "Transform: KNearestNeighbors(points_key=coords, queries_key=coords, k=8)\n",
      "\n",
      "After transform:\n",
      "  Fields: ['features', 'coords', 'neighbors_indices', 'neighbors_distances', 'neighbors_coords', 'neighbors_features']\n",
      "  edge_index shape: torch.Size([65795, 8])\n",
      "\n",
      "Graph structure:\n",
      "  Nodes: 65795\n",
      "  Edges / node: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pointcloud_data_path = \"./output/pointcloud_data/\"\n",
    "\n",
    "reader = ZarrReader(path=pointcloud_data_path, group_pattern=\"*.zarr\")\n",
    "data, metadata = reader[0]\n",
    "\n",
    "print(f\"Loaded sample with {data['coords'].shape[0]} points\")\n",
    "print(f\"Fields: {list(data.keys())}\")\n",
    "print()\n",
    "\n",
    "# Create and apply the KNN edge transform\n",
    "knn_transform = KNearestNeighbors(\n",
    "    points_key=\"coords\",\n",
    "    queries_key=\"coords\",  # Apply the kNN to itself.\n",
    "    k=8,  # It will find the 8 nearest edges\n",
    "    extract_keys=[\"features\"],\n",
    "    drop_first_neighbor=False,  # Because we're applying this on itself, the \"first\" closest neighbor is always the point itself.  You could drop this in the selections\n",
    ")\n",
    "print(f\"Transform: {knn_transform}\")\n",
    "print()\n",
    "\n",
    "data_with_edges = knn_transform(data)\n",
    "\n",
    "edge_index = \"neighbors_indices\"\n",
    "\n",
    "print(\"After transform:\")\n",
    "print(f\"  Fields: {list(data_with_edges.keys())}\")\n",
    "print(f\"  edge_index shape: {data_with_edges[edge_index].shape}\")\n",
    "print()\n",
    "\n",
    "# Verify graph structure\n",
    "n_nodes = data_with_edges[\"coords\"].shape[0]\n",
    "n_edges = data_with_edges[edge_index].shape[1]\n",
    "\n",
    "print(f\"Graph structure:\")\n",
    "print(f\"  Nodes: {n_nodes}\")\n",
    "print(f\"  Edges / node: {n_edges}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a20d9-eb94-4098-a21b-4bd8f3e4c22f",
   "metadata": {},
   "source": [
    "Note that the `kNearestNeighbors` transform is able to automatically apply the selection to not just generate the indicies, but it can also compute the distances and select the coordinates.  Further, you can pass in other tensor keys and it will apply the selection for those features too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f445e2-9a75-4fce-9392-21fc0de2608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65795, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(data_with_edges[\"neighbors_features\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc194a-a05b-43f7-a00c-b854654c45e4",
   "metadata": {},
   "source": [
    "## Combining Batches of Data\n",
    "\n",
    "If we want to have a batch size greater than 1 with this data, we can build a custom collator for the `physicsnemo` DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c38a07-5ae3-4c40-a812-51f0d0127e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyGCollator(Collator):\n",
    "    \"\"\"\n",
    "    Collator that batches graphs using PyTorch Geometric's built-in batching.\n",
    "\n",
    "    This collator converts each sample to a PyG Data object, then uses\n",
    "    `Batch.from_data_list()` to handle all the complexity of graph batching:\n",
    "    - Node features are concatenated: (N1 + N2 + ... + Nb, F)\n",
    "    - Edge indices are automatically offset and concatenated\n",
    "    - A `batch` tensor tracks which nodes belong to which graph\n",
    "\n",
    "    Example:\n",
    "        Graph 0: 100 nodes, edges [[0,1,2], [1,2,0]]\n",
    "        Graph 1: 150 nodes, edges [[0,1], [1,0]]\n",
    "\n",
    "        Batched (handled automatically by PyG):\n",
    "        - nodes: (250, F)\n",
    "        - edge_index: [[0,1,2,100,101], [1,2,0,101,100]]  # Graph 1 offset by 100\n",
    "        - batch: [0]*100 + [1]*150\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge_index_key: str = \"edge_index\",\n",
    "        collate_metadata: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the PyG-style collator.\n",
    "\n",
    "        Args:\n",
    "            edge_index_key: Key for edge indices in the input data.\n",
    "                Expected shape is [num_nodes, k] from KNN, which will be\n",
    "                converted to PyG's [2, num_edges] format.\n",
    "        \"\"\"\n",
    "        self.collate_metadata = collate_metadata\n",
    "        self.edge_index_key = edge_index_key\n",
    "\n",
    "    @staticmethod\n",
    "    def knn_to_edge_index(knn_indices: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert KNN indices to PyG edge_index format.\n",
    "\n",
    "        Args:\n",
    "            knn_indices: Tensor of shape [num_nodes, k] where each row contains\n",
    "                the k nearest neighbor indices for that node.\n",
    "\n",
    "        Returns:\n",
    "            edge_index: Tensor of shape [2, num_nodes * k] in PyG COO format,\n",
    "                where edge_index[0] is source nodes and edge_index[1] is target nodes.\n",
    "        \"\"\"\n",
    "        num_nodes, k = knn_indices.shape\n",
    "        # Source nodes: each node index repeated k times\n",
    "        source = torch.arange(num_nodes, device=knn_indices.device).repeat_interleave(k)\n",
    "        # Target nodes: flatten the KNN indices\n",
    "        target = knn_indices.reshape(-1)\n",
    "        return torch.stack([source, target], dim=0)\n",
    "\n",
    "    def __call__(\n",
    "        self, samples: Sequence[tuple[dict, dict[str, Any]]]\n",
    "    ) -> tuple[PyGBatch, list[dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Collate graphs into a batched PyG Batch object.\n",
    "\n",
    "        Args:\n",
    "            samples: Sequence of (TensorDict/dict, metadata) tuples.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (PyG Batch, list of metadata dicts).\n",
    "        \"\"\"\n",
    "        if not samples:\n",
    "            raise ValueError(\"Cannot collate empty sequence of samples\")\n",
    "\n",
    "        # Separate data and metadata\n",
    "        data_list = [data for data, _ in samples]\n",
    "\n",
    "        # Convert each sample to a PyG Data object\n",
    "        pyg_data_list = []\n",
    "        for data in data_list:\n",
    "            # Build kwargs for PyG Data, renaming edge_index_key to 'edge_index'\n",
    "            data_kwargs = {}\n",
    "            for key in data.keys():\n",
    "                tensor = data[key]\n",
    "                if key == self.edge_index_key:\n",
    "                    # Convert from KNN format [num_nodes, k] to PyG format [2, num_edges]\n",
    "                    data_kwargs[\"edge_index\"] = self.knn_to_edge_index(tensor)\n",
    "                else:\n",
    "                    data_kwargs[key] = tensor\n",
    "\n",
    "            pyg_data_list.append(PyGData(**data_kwargs))\n",
    "\n",
    "        # Use PyG's built-in batching - handles edge index offsetting automatically\n",
    "        batched_data = PyGBatch.from_data_list(pyg_data_list)\n",
    "\n",
    "        if self.collate_metadata:\n",
    "            metadata_list = [meta for _, meta in samples]\n",
    "            return batched_data, list(metadata_list)\n",
    "        else:\n",
    "            return batched_data\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PyGCollator(edge_index_key={self.edge_index_key})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d00eb-94d5-4780-af98-14a9c3248270",
   "metadata": {},
   "source": [
    "Let's convert the reader + kNN into a dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50deb0f9-9ee4-4b35-b17e-20cdad5411c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    reader=reader,\n",
    "    transforms=knn_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d85cfbd-197f-4127-a63c-68eba944c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorDict(\n",
       "     fields={\n",
       "         coords: Tensor(shape=torch.Size([65795, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         features: Tensor(shape=torch.Size([65795, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_coords: Tensor(shape=torch.Size([65795, 8, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_distances: Tensor(shape=torch.Size([65795, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_features: Tensor(shape=torch.Size([65795, 8, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_indices: Tensor(shape=torch.Size([65795, 8]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "     batch_size=torch.Size([]),\n",
       "     device=cpu,\n",
       "     is_shared=False),\n",
       " {'source_file': '/Users/coreya/physicsnemo/examples/minimal/datapipes/output/pointcloud_data/sample_000000.zarr',\n",
       "  'source_filename': 'sample_000000.zarr',\n",
       "  'index': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first two data items:\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d6569b-f290-43c8-b2ff-de9737a8d768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorDict(\n",
       "     fields={\n",
       "         coords: Tensor(shape=torch.Size([50860, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         features: Tensor(shape=torch.Size([50860, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_coords: Tensor(shape=torch.Size([50860, 8, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_distances: Tensor(shape=torch.Size([50860, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_features: Tensor(shape=torch.Size([50860, 8, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "         neighbors_indices: Tensor(shape=torch.Size([50860, 8]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "     batch_size=torch.Size([]),\n",
       "     device=cpu,\n",
       "     is_shared=False),\n",
       " {'source_file': '/Users/coreya/physicsnemo/examples/minimal/datapipes/output/pointcloud_data/sample_000001.zarr',\n",
       "  'source_filename': 'sample_000001.zarr',\n",
       "  'index': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa9dae-465b-4dc8-ad5b-ef2dc9565009",
   "metadata": {},
   "source": [
    "Apply the collation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e9e423-7fd4-4e4d-a1b2-4a4e4298ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coreya/physicsnemo/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:187: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'neighbors_features', 'neighbors_coords', 'coords', 'neighbors_distances', 'features', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  return sum([v.num_nodes for v in self.node_stores])\n",
      "/Users/coreya/physicsnemo/.venv/lib/python3.12/site-packages/torch_geometric/data/collate.py:142: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'neighbors_features', 'neighbors_coords', 'coords', 'neighbors_distances', 'features', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  repeats = [store.num_nodes or 0 for store in stores]\n"
     ]
    }
   ],
   "source": [
    "collator = PyGCollator(edge_index_key=\"neighbors_indices\")\n",
    "\n",
    "batch_gnn_inputs = collator([dataset[0], dataset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ea22c5-3379-4a46-8b9d-192dd1ce62db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 933240], features=[116655, 8], coords=[116655, 3], neighbors_distances=[116655, 8], neighbors_coords=[116655, 8, 3], neighbors_features=[116655, 8, 8], batch=[116655], ptr=[3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b3129-c984-47af-bd6f-8362271dd897",
   "metadata": {},
   "source": [
    "Of course, you can absolutely build this all in one pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8643a051-3b83-4022-8740-642b039779c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    "    collate_metadata=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924de74e-0740-4c94-8ddf-cdd81b23188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: DataBatch(edge_index=[2, 2543888], features=[317986, 8], coords=[317986, 3], neighbors_distances=[317986, 8], neighbors_coords=[317986, 8, 3], neighbors_features=[317986, 8, 8], batch=[317986], ptr=[5])\n",
      "1: DataBatch(edge_index=[2, 2685848], features=[335731, 8], coords=[335731, 3], neighbors_distances=[335731, 8], neighbors_coords=[335731, 8, 3], neighbors_features=[335731, 8, 8], batch=[335731], ptr=[5])\n",
      "2: DataBatch(edge_index=[2, 2306776], features=[288347, 8], coords=[288347, 3], neighbors_distances=[288347, 8], neighbors_coords=[288347, 8, 3], neighbors_features=[288347, 8, 8], batch=[288347], ptr=[5])\n",
      "3: DataBatch(edge_index=[2, 1951112], features=[243889, 8], coords=[243889, 3], neighbors_distances=[243889, 8], neighbors_coords=[243889, 8, 3], neighbors_features=[243889, 8, 8], batch=[243889], ptr=[5])\n",
      "4: DataBatch(edge_index=[2, 2364192], features=[295524, 8], coords=[295524, 3], neighbors_distances=[295524, 8], neighbors_coords=[295524, 8, 3], neighbors_features=[295524, 8, 8], batch=[295524], ptr=[5])\n",
      "5: DataBatch(edge_index=[2, 1974296], features=[246787, 8], coords=[246787, 3], neighbors_distances=[246787, 8], neighbors_coords=[246787, 8, 3], neighbors_features=[246787, 8, 8], batch=[246787], ptr=[5])\n",
      "6: DataBatch(edge_index=[2, 2118048], features=[264756, 8], coords=[264756, 3], neighbors_distances=[264756, 8], neighbors_coords=[264756, 8, 3], neighbors_features=[264756, 8, 8], batch=[264756], ptr=[5])\n",
      "7: DataBatch(edge_index=[2, 1944168], features=[243021, 8], coords=[243021, 3], neighbors_distances=[243021, 8], neighbors_coords=[243021, 8, 3], neighbors_features=[243021, 8, 8], batch=[243021], ptr=[5])\n",
      "8: DataBatch(edge_index=[2, 2028248], features=[253531, 8], coords=[253531, 3], neighbors_distances=[253531, 8], neighbors_coords=[253531, 8, 3], neighbors_features=[253531, 8, 8], batch=[253531], ptr=[5])\n",
      "9: DataBatch(edge_index=[2, 2577656], features=[322207, 8], coords=[322207, 3], neighbors_distances=[322207, 8], neighbors_coords=[322207, 8, 3], neighbors_features=[322207, 8, 8], batch=[322207], ptr=[5])\n",
      "10: DataBatch(edge_index=[2, 2710024], features=[338753, 8], coords=[338753, 3], neighbors_distances=[338753, 8], neighbors_coords=[338753, 8, 3], neighbors_features=[338753, 8, 8], batch=[338753], ptr=[5])\n",
      "11: DataBatch(edge_index=[2, 2035488], features=[254436, 8], coords=[254436, 3], neighbors_distances=[254436, 8], neighbors_coords=[254436, 8, 3], neighbors_features=[254436, 8, 8], batch=[254436], ptr=[5])\n",
      "12: DataBatch(edge_index=[2, 2536136], features=[317017, 8], coords=[317017, 3], neighbors_distances=[317017, 8], neighbors_coords=[317017, 8, 3], neighbors_features=[317017, 8, 8], batch=[317017], ptr=[5])\n",
      "13: DataBatch(edge_index=[2, 2146464], features=[268308, 8], coords=[268308, 3], neighbors_distances=[268308, 8], neighbors_coords=[268308, 8, 3], neighbors_features=[268308, 8, 8], batch=[268308], ptr=[5])\n",
      "14: DataBatch(edge_index=[2, 2292536], features=[286567, 8], coords=[286567, 3], neighbors_distances=[286567, 8], neighbors_coords=[286567, 8, 3], neighbors_features=[286567, 8, 8], batch=[286567], ptr=[5])\n",
      "15: DataBatch(edge_index=[2, 2341168], features=[292646, 8], coords=[292646, 3], neighbors_distances=[292646, 8], neighbors_coords=[292646, 8, 3], neighbors_features=[292646, 8, 8], batch=[292646], ptr=[5])\n",
      "16: DataBatch(edge_index=[2, 2019352], features=[252419, 8], coords=[252419, 3], neighbors_distances=[252419, 8], neighbors_coords=[252419, 8, 3], neighbors_features=[252419, 8, 8], batch=[252419], ptr=[5])\n",
      "17: DataBatch(edge_index=[2, 2610088], features=[326261, 8], coords=[326261, 3], neighbors_distances=[326261, 8], neighbors_coords=[326261, 8, 3], neighbors_features=[326261, 8, 8], batch=[326261], ptr=[5])\n",
      "18: DataBatch(edge_index=[2, 2727920], features=[340990, 8], coords=[340990, 3], neighbors_distances=[340990, 8], neighbors_coords=[340990, 8, 3], neighbors_features=[340990, 8, 8], batch=[340990], ptr=[5])\n",
      "19: DataBatch(edge_index=[2, 2346040], features=[293255, 8], coords=[293255, 3], neighbors_distances=[293255, 8], neighbors_coords=[293255, 8, 3], neighbors_features=[293255, 8, 8], batch=[293255], ptr=[5])\n",
      "20: DataBatch(edge_index=[2, 2802048], features=[350256, 8], coords=[350256, 3], neighbors_distances=[350256, 8], neighbors_coords=[350256, 8, 3], neighbors_features=[350256, 8, 8], batch=[350256], ptr=[5])\n",
      "21: DataBatch(edge_index=[2, 2141776], features=[267722, 8], coords=[267722, 3], neighbors_distances=[267722, 8], neighbors_coords=[267722, 8, 3], neighbors_features=[267722, 8, 8], batch=[267722], ptr=[5])\n",
      "22: DataBatch(edge_index=[2, 2060576], features=[257572, 8], coords=[257572, 3], neighbors_distances=[257572, 8], neighbors_coords=[257572, 8, 3], neighbors_features=[257572, 8, 8], batch=[257572], ptr=[5])\n",
      "23: DataBatch(edge_index=[2, 1973472], features=[246684, 8], coords=[246684, 3], neighbors_distances=[246684, 8], neighbors_coords=[246684, 8, 3], neighbors_features=[246684, 8, 8], batch=[246684], ptr=[5])\n",
      "24: DataBatch(edge_index=[2, 2510560], features=[313820, 8], coords=[313820, 3], neighbors_distances=[313820, 8], neighbors_coords=[313820, 8, 3], neighbors_features=[313820, 8, 8], batch=[313820], ptr=[5])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch_gnn in enumerate(dataloader):\n",
    "    print(f\"{idx}: {batch_gnn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803a59a-e49d-4c2e-8626-8b1b8c13172f",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "Physicsnemo's datapipes abstraction, as we've seen in these first 3 tutorials, offers flexibility at multiple levels.  You can individually configure how to _read_ data, how to manipulate individual data samples, and how to merge data samples into a batch.  You can also extend all of these tools with custom implementations: readers have just a few methods to override, and transforms only need to implement one function, and we saw in this tutorial how to apply custom collation logic to output onto PyG graphs.\n",
    "\n",
    "In all of this, we've traded flexibility for configuration verbosity: what can be accomplished in in a few lines of python for a one off research script takes more configuration in physicsnemo, though with an added benefit of checks and testing of your datapipe.  However, there is an additional technique for deploying your datapipe: configure entirely in `hydra` and instantiate the objects directly in one line of python.  We'll see that next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
